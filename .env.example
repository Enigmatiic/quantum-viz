# =============================================================================
# QUANTUM VIZ - Configuration des variables d'environnement
# =============================================================================
# Copiez ce fichier vers .env et remplissez les valeurs

# =============================================================================
# API KEYS
# =============================================================================

# Anthropic Claude (recommandé pour la validation de sécurité)
ANTHROPIC_API_KEY=sk-ant-api03-xxxxx

# OpenAI (alternative)
# OPENAI_API_KEY=sk-xxxxx

# =============================================================================
# CONFIGURATION OLLAMA (local)
# =============================================================================

# URL du serveur Ollama (défaut: http://localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434

# Modèle Ollama par défaut (llama3.2, codellama, deepseek-coder, mistral, etc.)
OLLAMA_MODEL=llama3.2

# =============================================================================
# CHOIX DE L'IA PAR MODULE
# =============================================================================
# Valeurs possibles: ollama, anthropic, openai, none

# IA pour la validation de sécurité (analyse des vulnérabilités)
# Recommandé: anthropic (Claude) pour la meilleure précision
AI_SECURITY_PROVIDER=anthropic

# IA pour la détection d'architecture
# Recommandé: ollama (local) pour réduire les coûts
AI_ARCHITECTURE_PROVIDER=ollama

# IA pour la classification des fichiers
# Recommandé: ollama (local) ou none pour une classification rapide
AI_CLASSIFICATION_PROVIDER=ollama

# IA pour l'explication des flux
# Recommandé: ollama ou anthropic selon le besoin de qualité
AI_FLOW_PROVIDER=ollama

# =============================================================================
# OPTIONS DE SÉCURITÉ
# =============================================================================

# Activer la validation AI automatique (true/false)
AI_SECURITY_ENABLED=true

# Nombre max de vulnérabilités à envoyer à l'AI (contrôle des coûts)
MAX_VULNS_FOR_AI=50

# =============================================================================
# OPTIONS AVANCÉES
# =============================================================================

# Timeout pour les requêtes Ollama (ms)
# OLLAMA_TIMEOUT=120000

# Température pour la génération (0.0 - 1.0)
# AI_TEMPERATURE=0.7

# Mode verbose pour le debug
# VERBOSE=true
